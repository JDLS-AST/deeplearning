{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this section we'll learn about how to compare the results of neural networks and optimize the weights of the network for future usage\n",
    "\n",
    "def compare(weights, bias):\n",
    "    pass\n",
    "\n",
    "def optimize(weights, bias):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30250000000000005"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's measure the error and find out!\n",
    "weight_knob = 0.5\n",
    "input = 0.5\n",
    "goal_pred = 0.8\n",
    "\n",
    "pred = input * weight_knob\n",
    "error = (goal_pred - pred) ** 2\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022499999999999975\n"
     ]
    }
   ],
   "source": [
    "weight = 0.1\n",
    "lr = 0.1\n",
    "\n",
    "def neural_network(input, weight):\n",
    "    return input * weight\n",
    "\n",
    "no_of_toes = [8.5]\n",
    "win_or_lose_binary = [1] # win\n",
    "\n",
    "input = no_of_toes[0]\n",
    "true = win_or_lose_binary[0]\n",
    "\n",
    "pred = neural_network(input, weight)\n",
    "error = (true - pred) ** 2\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49000000000000027\n"
     ]
    }
   ],
   "source": [
    "p_up = neural_network(input, weight + lr)\n",
    "e_up = (true - p_up) ** 2\n",
    "print(e_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05522499999999994\n"
     ]
    }
   ],
   "source": [
    "# making a prediction with lower weight and evaluating error\n",
    "lr = 0.01\n",
    "p_down = neural_network(input, weight - lr)\n",
    "e_down = (true - p_down) ** 2\n",
    "print(e_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.2505002499999999 Prediction: 0.29950000000000004\n",
      "Error: 0.20295024999999997 Prediction: 0.3495000000000001\n",
      "Error: 0.16040024999999994 Prediction: 0.39950000000000013\n",
      "Error: 0.12285024999999991 Prediction: 0.4495000000000002\n",
      "Error: 0.09030024999999989 Prediction: 0.4995000000000002\n",
      "Error: 0.06275025000000264 Prediction: 0.5494999999999948\n",
      "Error: 0.04020025000000432 Prediction: 0.5994999999999893\n",
      "Error: 0.022650250000004903 Prediction: 0.6494999999999838\n",
      "Error: 0.01010025000000438 Prediction: 0.6994999999999783\n",
      "Error: 0.0025502500000027573 Prediction: 0.7494999999999727\n"
     ]
    }
   ],
   "source": [
    "# hot and cold learning\n",
    "weight = 0.5\n",
    "input = 0.5\n",
    "goal_pred = 0.8\n",
    "\n",
    "step_amount = 0.001\n",
    "\n",
    "for iteration in range(1000):\n",
    "    prediction = input * weight\n",
    "    error = (goal_pred - prediction) ** 2\n",
    "\n",
    "    if (iteration + 1) % 100 == 0:\n",
    "        print(f'Error: {error} Prediction: {prediction}')\n",
    "\n",
    "    up_prediction = input * (weight + step_amount)\n",
    "    up_error = (goal_pred - up_prediction) ** 2\n",
    "\n",
    "    down_prediction = input * (weight - step_amount)\n",
    "    down_error = (goal_pred - down_prediction) ** 2\n",
    "\n",
    "    if up_error < error:\n",
    "        weight += step_amount\n",
    "    elif down_error < error:\n",
    "        weight -= step_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.03028415679931642 Prediction: 0.6259765625\n",
      "Error: 0.0017054073093822882 Prediction: 0.7587034225463867\n",
      "Error: 9.603747960254256e-05 Prediction: 0.7902001285925507\n",
      "Error: 5.408208020258491e-06 Prediction: 0.7976744445781151\n"
     ]
    }
   ],
   "source": [
    "# above method has many downsides, so we'll use gradient descent\n",
    "weight = 0.5\n",
    "input = 0.5\n",
    "goal_pred = 0.8\n",
    "\n",
    "for iteration in range(20):\n",
    "    pred = input * weight\n",
    "    error = (pred - goal_pred) ** 2\n",
    "    direction_and_amount = (pred - goal_pred) * input # -> it's what we call gradient (or slope)\n",
    "    \"\"\"\n",
    "    Can also write direction and amount thing as following:\n",
    "    delta = goal_pred - pred\n",
    "    weight_delta = delta * input \n",
    "    weight -= weight_delta * alpha -> (generally it's what we call learning rate)\n",
    "    \"\"\"\n",
    "    weight -= direction_and_amount\n",
    "\n",
    "    if (iteration + 1) % 5 == 0: \n",
    "        print(f'Error: {error} Prediction: {pred}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mltut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
