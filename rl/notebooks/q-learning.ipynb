{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 2, 0], [0, 0, 0, 3]]\n"
     ]
    }
   ],
   "source": [
    "# Create a Q Learning Algo from scratch\n",
    "\n",
    "grid = [\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 1, 0, 0],\n",
    "    [0, 0, 2, 0],\n",
    "    [0, 0, 0, 3]\n",
    "]\n",
    "\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [(i, j) for i in range(4) for j in range(4)]\n",
    "actions = [(0, 1), (1, 0), (0, -1), (-1, 0)] # Right, Down, Left, Up\n",
    "q_table = {(state, action): 0 for state in states for action in actions}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Parameters\n",
    "alpha = 0.5 # Learning rate\n",
    "gamma = 0.95 # Discount factor\n",
    "epsilon = 0.1 # Exploration rate\n",
    "num_episodes = 10000\n",
    "\n",
    "# Function to get the next state and reward\n",
    "def get_next_state_and_reward(state, action):\n",
    "    x, y = state\n",
    "    dx, dy = action\n",
    "    next_x, next_y = x + dx, y + dy\n",
    "    \n",
    "    # Check for out-of-bounds or hitting a wall\n",
    "    if next_x < 0 or next_x >= 4 or next_y < 0 or next_y >= 4 or grid[next_x][next_y] == 1:\n",
    "        return state, -1 # Penalty for hitting a wall\n",
    "    \n",
    "    reward = -1 # Default reward\n",
    "    if grid[next_x][next_y] == 2:\n",
    "        reward = 100 # Reward for reaching the goal\n",
    "    elif grid[next_x][next_y] == 3:\n",
    "        reward = -100 # Penalty for hitting the starting point again\n",
    "    \n",
    "    return (next_x, next_y), reward\n",
    "\n",
    "# Q-Learning\n",
    "for episode in range(num_episodes):\n",
    "    state = (0, 0) # Start at the top-left corner\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = random.choice(actions) # Explore: choose a random action\n",
    "        else:\n",
    "            action = max(actions, key=lambda x: q_table[(state, x)]) # Exploit: choose the best action\n",
    "        \n",
    "        next_state, reward = get_next_state_and_reward(state, action)\n",
    "        \n",
    "        # Update Q-value\n",
    "        old_value = q_table[(state, action)]\n",
    "        next_max = max(q_table[(next_state, a)] for a in actions)\n",
    "        \n",
    "        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
    "        q_table[(state, action)] = new_value\n",
    "        \n",
    "        state = next_state\n",
    "        \n",
    "        if grid[state[0]][state[1]] == 2 or grid[state[0]][state[1]] == 3:\n",
    "            done = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path taken by the agent: [(0, 0), (0, 1), (0, 2), (1, 2)]\n"
     ]
    }
   ],
   "source": [
    "def test_agent():\n",
    "    state = (0, 0)\n",
    "    done = False\n",
    "    path = []\n",
    "    \n",
    "    while not done:\n",
    "        action = max(actions, key=lambda x: q_table[(state, x)])\n",
    "        next_state, reward = get_next_state_and_reward(state, action)\n",
    "        path.append(state)\n",
    "        state = next_state\n",
    "        \n",
    "        if grid[state[0]][state[1]] == 2 or grid[state[0]][state[1]] == 3:\n",
    "            done = True\n",
    "    \n",
    "    return path\n",
    "\n",
    "# Test the agent\n",
    "path = test_agent()\n",
    "print(\"Path taken by the agent:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlprep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
